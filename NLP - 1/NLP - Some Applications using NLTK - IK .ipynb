{"cells":[{"cell_type":"markdown","id":"ed0982f4","metadata":{"id":"ed0982f4"},"source":["# Sentiment Analysis\n","### Using the Pre-Trained VADER Model\n","https://github.com/cjhutto/vaderSentiment\n","\n","VADER (Valence-Aware Dictionary for Sentiment Reasoning)\n","\n","This code first downloads the VADER lexicon using NLTK. Then it creates an instance of the SentimentIntensityAnalyzer, which will be used to classify the sentiment of the text. Then it loads a small dataset that includes a few examples of text along with their corresponding sentiment labels.\n","\n","For the classification, it uses the compound score provided by the VADER library, and checks if the score is above 0.05 for positive, below -0.05 for negative and in between for neutral.\n","\n","It is important to note that VADER is based on a lexicon and it is a rule-based approach, which may not always provide the best results in all cases, and you may need to tweak the code to suit your needs."]},{"cell_type":"code","execution_count":1,"id":"63523c44","metadata":{"id":"63523c44","executionInfo":{"status":"error","timestamp":1694062619057,"user_tz":-330,"elapsed":1809,"user":{"displayName":"Sanatan Sukhija","userId":"00318259453802622356"}},"outputId":"b4ca6b0a-440e-464d-9812-d0ae4046cc77","colab":{"base_uri":"https://localhost:8080/","height":741}},"outputs":[{"output_type":"error","ename":"LookupError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-c0ca6a0d9db5>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Instantiate the SentimentIntensityAnalyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mvader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lexicon_file)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mlexicon_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     ):\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexicon_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexicon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_lex_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVaderConstants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"]}],"source":["import nltk\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","\n","# Download the VADER lexicon\n","# nltk.download('vader_lexicon')\n","\n","# Instantiate the SentimentIntensityAnalyzer\n","vader = SentimentIntensityAnalyzer()"]},{"cell_type":"markdown","id":"134ff822","metadata":{"id":"134ff822"},"source":["VADER is a lexicon and rule-based feeling analysis instrument that is explicitly sensitive to suppositions communicated in web-based media. VADER utilizes a mix of lexical highlights (e.g., words) that are, for the most part, marked by their semantic direction as one or the other positive or negative. Thus, VADER not only tells about the Polarity score yet, in addition, it tells us concerning how positive or negative a conclusion is."]},{"cell_type":"markdown","id":"12f8278a","metadata":{"id":"12f8278a"},"source":["* VADER assigns a sentiment score to each lexicon. Every word in the vocabulary is appraised with respect to whether it is positive or negative, and, how +ve or -ve.\n","\n","* Note: Not every word (token) is present in the lexicon. The lexicon needs to have great inclusion of the words in your content, else, it will not be extremely accurate.\n","\n","## Let's apply VADER on a sample text."]},{"cell_type":"code","execution_count":null,"id":"c382e5ba","metadata":{"id":"c382e5ba","outputId":"89a98a3c-7a0a-454d-9a9e-ae9f3e5a6e48"},"outputs":[{"data":{"text/plain":["{'neg': 0.0, 'neu': 0.494, 'pos': 0.506, 'compound': 0.6239}"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["text = 'This is an amazing product!'\n","vader.polarity_scores(text) #Predict the polarity of the text\n","#You can see that VADER returns a total of 4 values in a dictionary."]},{"cell_type":"markdown","id":"aa78b9f1","metadata":{"id":"aa78b9f1"},"source":["> The first three keys {neg, neu, pos} denote the probability scores for the negative, neutral, and positive sentiment respectively.\n","\n","> The last value {'compound'} calculates the sum of all the lexicon ratings which have been **normalized between -1(most extreme negative) and +1 (most extreme positive)**"]},{"cell_type":"markdown","id":"31429d1b","metadata":{"id":"31429d1b"},"source":["# Let's analyze the ratings for the tokens in the input text"]},{"cell_type":"code","execution_count":null,"id":"4cebf66f","metadata":{"id":"4cebf66f","outputId":"c480ddb7-256f-4b00-9e1a-cc64c982d2f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["['This', 'is', 'an', 'amazing', 'product', '!']\n"]}],"source":["text = 'This is an amazing product!'\n","tokenized_sentence = nltk.word_tokenize(text)\n","print(tokenized_sentence)"]},{"cell_type":"markdown","id":"b8362235","metadata":{"id":"b8362235"},"source":["When VADER examines a piece of text, it verifies whether any of the words in the content are available in its lexicon."]},{"cell_type":"code","execution_count":null,"id":"aef4771b","metadata":{"id":"aef4771b","outputId":"c6fdbac5-56d0-4f3e-965a-4c75fc4f1d1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Positive: ['amazing', 0.5859]\n","Neutral: ['This', 0.0, 'is', 0.0, 'an', 0.0, 'product', 0.0, '!', 0.0]\n","Negative: []\n"]}],"source":["pos_word_list=[]\n","neu_word_list=[]\n","neg_word_list=[]\n","\n","for word in tokenized_sentence:\n","    if (vader.polarity_scores(word)['compound']) >= 0.05: #A positive word will have a score greater than 0.\n","        pos_word_list.append(word)\n","        pos_word_list.append(vader.polarity_scores(word)['compound'])\n","    elif (vader.polarity_scores(word)['compound']) <= -0.05: #A negative word will have a score less than 0.\n","        neg_word_list.append(word)\n","        neg_word_list.append(vader.polarity_scores(word)['compound'])\n","    else:\n","        neu_word_list.append(word)\n","        neu_word_list.append(vader.polarity_scores(word)['compound'])\n","\n","print('Positive:',pos_word_list)\n","print('Neutral:',neu_word_list)\n","print('Negative:',neg_word_list)\n","\n","# You can see that only the word 'amazing' was present in the lexicon with a rating of +0.5859.\n","# A score of 0 means that the word was not present in the lexicon."]},{"cell_type":"code","execution_count":null,"id":"9bd34a9d","metadata":{"id":"9bd34a9d","outputId":"d8ffc62d-08ae-449f-8ed0-7798deda991c"},"outputs":[{"data":{"text/plain":["{'neg': 0.0, 'neu': 0.494, 'pos': 0.506, 'compound': 0.6239}"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["sentiment = vader.polarity_scores(text)\n","sentiment"]},{"cell_type":"markdown","id":"aaf903e9","metadata":{"id":"aaf903e9"},"source":["The compound score is computed as the sum of ratings of the lexicons that have been **normalized between -1 (most extreme negative) and +1 (most extreme positive)**."]},{"cell_type":"code","execution_count":null,"id":"46846d3e","metadata":{"id":"46846d3e","outputId":"8a6aab17-fe5d-4e43-93ea-779941489570"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'neg': 0.0, 'neu': 0.494, 'pos': 0.506, 'compound': 0.6239}\n"]},{"data":{"text/plain":["'positive'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# decide the sentiment using the sentiment probabilities\n","# Choose the sentiment with the max probability\n","\n","text = 'This is an amazing product!'\n","sentiment_dict = vader.polarity_scores(text)\n","print(sentiment_dict)\n","\n","neg_prob  = sentiment_dict[\"neg\"]\n","pos_prob = sentiment_dict[\"pos\"]\n","neu_prob  = sentiment_dict[\"neu\"]\n","\n","#Find the sentiment with the max probability\n","ind = [neg_prob, pos_prob, neu_prob].index(max([neg_prob, pos_prob, neu_prob]))\n","\n","if(ind==0):\n","    predicted_sentiment = \"negative\"\n","elif(ind==1):\n","    predicted_sentiment = \"positive\"\n","else:\n","    predicted_sentiment = \"neutral\"\n","\n","predicted_sentiment"]},{"cell_type":"code","execution_count":null,"id":"4b0ec480","metadata":{"id":"4b0ec480","outputId":"3113e7fc-20c4-4ef4-e952-058d5302302e"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'neg': 0.0, 'neu': 0.494, 'pos': 0.506, 'compound': 0.6239}\n","Positive\n"]}],"source":["# You can also decide the sentiment using the compound score\n","\n","text = 'This is an amazing product!'\n","sentiment_dict = vader.polarity_scores(text)\n","print(sentiment_dict)\n","\n","if sentiment_dict['compound'] >= 0.05: #The threshold should be chosen carefully!\n","    print(\"Positive\")\n","\n","elif sentiment_dict['compound'] <= -0.05:\n","    print(\"Negative\")\n","\n","else :\n","    print(\"Neutral\")"]},{"cell_type":"code","execution_count":null,"id":"dd24ba65","metadata":{"id":"dd24ba65"},"outputs":[],"source":["# Taking a sample dataset\n","dataset = [(\"This is an amazing product!\", \"positive\"),\n","           (\"I hate this product!\", \"negative\"),\n","           (\"I am indifferent to this product.\", \"neutral\"),\n","           (\"I'm not sure how I feel about this product.\", \"neutral\"),\n","           (\"This product is terrible.\", \"negative\"),\n","          (\"Doesn't match match my expectations\",\"negative\"),\n","          (\"The product could be much better\",\"neutral\"),\n","          (\"I appreciate how terrible it is!\", \"negative\"),\n","          (\"I hate this product but I love the design\",\"neutral\")]"]},{"cell_type":"code","execution_count":null,"id":"24b4aa6c","metadata":{"id":"24b4aa6c","outputId":"8fe79df9-0796-4e1f-84bc-70d571995084"},"outputs":[{"name":"stdout","output_type":"stream","text":["-----------------------------\n","1) Text: Doesn't match match my expectations \n","Actual Sentiment: negative \n","Predicted Sentiment: neutral\n","-----------------------------\n","2) Text: I hate this product but I love the design \n","Actual Sentiment: neutral \n","Predicted Sentiment: positive\n","-----------------------------\n","\n","Accuracy on the dataset: 0.7777777777777778\n"]}],"source":["# Test the pre-trained vader classifier on the above dataset\n","#Evaluate the performance using the metric Accuracy\n","\n","correct = 0 #Counter for correctly predicted samples\n","incorrect = 0 #Counter for incorrectly predicted samples\n","total = 0 #Counter for total samples\n","for text, sentiment in dataset: #Each tuple in the dataset contains the <text> and the corresponding <sentiment>\n","    prediction = vader.polarity_scores(text)\n","\n","    neg_prob  = prediction[\"neg\"]\n","    pos_prob = prediction[\"pos\"]\n","    neu_prob  = prediction[\"neu\"]\n","\n","    ind = [neg_prob, pos_prob, neu_prob].index(max([neg_prob, pos_prob, neu_prob]))\n","    if(ind==0):\n","        predicted_sentiment = \"negative\"\n","    elif(ind==1):\n","        predicted_sentiment = \"positive\"\n","    else:\n","        predicted_sentiment = \"neutral\"\n","\n","    if predicted_sentiment == sentiment:\n","        #print(text, sentiment, predicted_sentiment)\n","        correct += 1\n","    total += 1\n","\n","    #For misclassified samples\n","    if predicted_sentiment != sentiment:\n","        incorrect = incorrect + 1\n","        print('-----------------------------')\n","        print(str(incorrect)+')',\"Text:\",text, '\\nActual Sentiment:',sentiment, \"\\nPredicted Sentiment:\",predicted_sentiment)\n","\n","print('-----------------------------\\n')\n","print(f\"Accuracy on the dataset: {correct/total}\")"]},{"cell_type":"markdown","id":"0db3209e","metadata":{"id":"0db3209e"},"source":["### More about VADER scoring here\n","https://github.com/cjhutto/vaderSentiment#code-examples"]},{"cell_type":"markdown","id":"b59d403f","metadata":{"id":"b59d403f"},"source":["# Word Sense Disambiguation (WSD)\n","Deals with determining the intended meaning of a word in a given context. It is the process of identifying the correct sense of a word from a set of possible senses, based on the context in which the word appears."]},{"cell_type":"code","execution_count":null,"id":"03583335","metadata":{"id":"03583335"},"outputs":[],"source":["# Install pre-requisites\n","\n","# Download the WordNet corpus\n","#nltk.download('wordnet')\n","\n","# Download the Lesk algorithm\n","#nltk.download('omw')"]},{"cell_type":"markdown","id":"b31db907","metadata":{"id":"b31db907"},"source":["\n","## Lesk Algorithm\n","\n","Performs the classic Lesk algorithm for Word Sense Disambiguation (WSD) using the definitions of the ambiguous word.\n","\n","Given an ambiguous word and the context in which the word occurs, Lesk returns a Synset with the highest number of overlapping words between the context sentence and different definitions from each Synset"]},{"cell_type":"code","execution_count":null,"id":"7d559c90","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7d559c90","executionInfo":{"status":"error","timestamp":1693712174599,"user_tz":-330,"elapsed":2090,"user":{"displayName":"Sanatan Sukhija","userId":"00318259453802622356"}},"outputId":"edae4ae2-21b4-49c3-df90-a77d34178b56"},"outputs":[{"output_type":"error","ename":"LookupError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-2416d4fdb4c9>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'I'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'went'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'to'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'the'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bank'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'to'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deposit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'money'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlesk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bank'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#'Bank' is the ambiguous word here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/wsd.py\u001b[0m in \u001b[0;36mlesk\u001b[0;34m(context_sentence, ambiguous_word, pos, synsets)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msynsets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0msynsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mambiguous_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"]}],"source":["from nltk.wsd import lesk\n","sentence = ['I', 'went', 'to', 'the', 'bank', 'to', 'deposit', 'money', '.']\n","\n","print(lesk(sentence, 'bank'))#'Bank' is the ambiguous word here."]},{"cell_type":"code","execution_count":null,"id":"9ee5b11a","metadata":{"id":"9ee5b11a","outputId":"0b859c38-ca37-4232-a78a-a61a239a89a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Synset('bank.n.01') sloping land (especially the slope beside a body of water)\n","Synset('depository_financial_institution.n.01') a financial institution that accepts deposits and channels the money into lending activities\n","Synset('bank.n.03') a long ridge or pile\n","Synset('bank.n.04') an arrangement of similar objects in a row or in tiers\n","Synset('bank.n.05') a supply or stock held in reserve for future use (especially in emergencies)\n","Synset('bank.n.06') the funds held by a gambling house or the dealer in some gambling games\n","Synset('bank.n.07') a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n","Synset('savings_bank.n.02') a container (usually with a slot in the top) for keeping money at home\n","Synset('bank.n.09') a building in which the business of banking transacted\n","Synset('bank.n.10') a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n","Synset('bank.v.01') tip laterally\n","Synset('bank.v.02') enclose with a bank\n","Synset('bank.v.03') do business with a bank or keep an account at a bank\n","Synset('bank.v.04') act as the banker in a game or in gambling\n","Synset('bank.v.05') be in the banking business\n","Synset('deposit.v.02') put into a bank account\n","Synset('bank.v.07') cover with ashes so to control the rate of burning\n","Synset('trust.v.01') have confidence or faith in\n"]}],"source":["from nltk.corpus import wordnet as wn\n","#Let's see all the possible definitions of the word 'Bank'\n","for ss in wn.synsets('bank'):\n","    print(ss, ss.definition())"]},{"cell_type":"code","execution_count":null,"id":"1c10f63d","metadata":{"id":"1c10f63d","outputId":"c1ff4e73-e014-4f0a-e6fa-342e01adab48"},"outputs":[{"name":"stdout","output_type":"stream","text":["Synset('able.s.04')\n","having a strong healthy body\n"]}],"source":["sent = 'people should be able to marry a person of their choice'.split()\n","print(lesk(sent, 'able'))\n","print(lesk(sent, 'able').definition())"]},{"cell_type":"code","execution_count":null,"id":"5fa54900","metadata":{"id":"5fa54900","outputId":"03462405-0a04-4892-9439-398d0bff4c64"},"outputs":[{"name":"stdout","output_type":"stream","text":["Synset('able.a.01')\n","(usually followed by `to') having the necessary means or skill or know-how or authority to do something\n"]}],"source":["#When calling lesk, if you can provide the part of speech for the word\n","# to be disambiguated it can provide better results.\n","print(lesk(sent, 'able', pos='a')) #pos argument denotes part of speech. Here, 'a' is an adjective.\n","print(lesk(sent, 'able', pos='a').definition())"]},{"cell_type":"code","execution_count":null,"id":"315446e3","metadata":{"id":"315446e3","outputId":"d6c1ea1b-bcf4-4eca-99f9-617034be037b"},"outputs":[{"name":"stdout","output_type":"stream","text":["bank : do business with a bank or keep an account at a bank\n","Examples: ['Where do you bank in this town?']\n","\n","eve : the latter part of the day (the period of decreasing daylight from late afternoon until nightfall)\n","Examples: ['he enjoyed the evening light across the lake']\n","\n","play : (in games or plays or other performances) the time during which play proceeds\n","Examples: ['rain stopped play in the 4th inning']\n","\n","report : the general estimation that the public has for a person\n","Examples: ['he acquired a reputation as an actor before he started writing', 'he was a person of bad report']\n","\n"]}],"source":["# Input text\n","text_examples = [(\"I have a bank account with the SBI bank\", \"bank\"),\n","                 (\"We went for a picnic on the eve of new year\",\"eve\"),\n","                 (\"I play the guitar\", \"play\"),\n","                (\"I prepared a report for my manager\",'report')]\n","\n","# Perform word sense disambiguation using the Lesk algorithm\n","from nltk.wsd import lesk\n","for text, target_word in text_examples:\n","    tokens = nltk.word_tokenize(text)\n","    sense = lesk(tokens, target_word)# Provide the pos for better results\n","    if sense:\n","        print(f'{target_word} : {sense.definition()}')\n","        print(f'Examples: {sense.examples()}')\n","        print()"]},{"cell_type":"code","execution_count":null,"id":"fabddeee","metadata":{"id":"fabddeee"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}